{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0671d0-5110-4c3d-a296-0dd12d190fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import mysql.connector    # installing pymysql and mysql-connector package for making connections to database server\n",
    "!pip install pymysql  \n",
    "!pip install mysql-connector\n",
    "pd.set_option('display.max_columns',None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "cursor=connection.cursor()\n",
    "cursor.execute('show databases')\n",
    "for i in cursor:\n",
    "    print(i)\n",
    "project= pd.read_sql_query(\"show tables\",connection)\n",
    "print(project)\n",
    "data = pd.read_sql_query(\"select * from dataset_list\",connection)\n",
    "data\n",
    "data.info()\n",
    "data.head()\n",
    "data.tail()\n",
    "data.shape\n",
    "data.describe()\n",
    "data.columns\n",
    "data.select_dtypes(include=['int64','float64']).columns\n",
    "data.select_dtypes(include=['object']).columns\n",
    "import sweetviz as sv # library for univariant analysis\n",
    "my_report=sv.analyze(data) # passing the original dataframe\n",
    "my_report.show_html() # arguments will generate to// the library\n",
    "data.select_dtypes(include=['object','category']).columns.tolist()\n",
    "for i in data.columns:\n",
    "    data[i].replace(\"\", np.nan,inplace=True)\n",
    "data.isna().sum() #cheking the Nan values\n",
    "# Dropping Column which have high null values.\n",
    "data.drop(columns=['Reopen_Time'], inplace=True)\n",
    "data.drop(columns=['No_of_Related_Incidents'], inplace=True)\n",
    "data.drop(columns=['No_of_Related_Changes'], inplace=True)\n",
    "data.drop(columns=['Related_Change'], inplace=True)\n",
    "# lets fill all the null values with statistical methods\n",
    "data.loc[data[\"CI_Cat\"].isnull(),\"CI_Cat\"] = 'application'\n",
    "data.loc[data[\"CI_Subcat\"].isnull(),\"CI_Subcat\"] = \"Server Based Application\"\n",
    "data.loc[data[\"No_of_Reassignments\"].isnull(),\"No_of_Reassignments\"] =0\n",
    "data.loc[data[\"Handle_Time_hrs\"].isnull(),\"Handle_Time_hrs\"] = 0\n",
    "data.loc[data[\"Closure_Code\"].isnull(),\"Closure_Code\"] = \"Other\"\n",
    "data.loc[data[\"No_of_Related_Interactions\"].isnull(),\"No_of_Related_Interactions\"] = 1\n",
    "data.isnull().sum()\n",
    "data.duplicated().sum() #checking duplicates\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc=LabelEncoder()\n",
    "#CI_Name\n",
    "data.CI_Name =enc.fit_transform(data.CI_Name )\n",
    "\n",
    "#CI_Cat\n",
    "data.CI_Cat =enc.fit_transform(data.CI_Cat )\n",
    "\n",
    "#CI_Subc\n",
    "data.CI_Subcat =enc.fit_transform(data.CI_Subcat )\n",
    "\n",
    "#WBS\n",
    "data.WBS =enc.fit_transform(data.WBS )\n",
    "\n",
    "#Incident_ID\n",
    "data.Incident_ID =enc.fit_transform(data.Incident_ID )\n",
    "\n",
    "#Status\n",
    "data.Status =enc.fit_transform(data.Status )\n",
    "\n",
    "#Impact\n",
    "data.Impact =enc.fit_transform(data.Impact )\n",
    "\n",
    "#Urgency\n",
    "data.Urgency =enc.fit_transform(data.Urgency )\n",
    "\n",
    "#Priority\n",
    "data.Priority =enc.fit_transform(data.Priority )\n",
    "\n",
    "#number_cnt\n",
    "data.number_cnt =enc.fit_transform(data.number_cnt )\n",
    "\n",
    "#Category\n",
    "data.Category =enc.fit_transform(data.Category )\n",
    "\n",
    "#number_cnt\n",
    "data.number_cnt =enc.fit_transform(data.number_cnt )\n",
    "\n",
    "#Category\n",
    "data.Category =enc.fit_transform(data.Category )\n",
    "\n",
    "#KB_number\n",
    "data.KB_number =enc.fit_transform(data.KB_number )\n",
    "\n",
    "#Alert_Status\n",
    "data.Alert_Status =enc.fit_transform(data.Alert_Status )\n",
    "\n",
    "\n",
    "#Open_Time\n",
    "data.Open_Time =enc.fit_transform(data.Open_Time )\n",
    "\n",
    "\n",
    "#Resolved_Time\n",
    "data.Resolved_Time =enc.fit_transform(data.Resolved_Time )\n",
    "\n",
    "#Close_Time\n",
    "data.Close_Time =enc.fit_transform(data.Close_Time )\n",
    "\n",
    "\n",
    "\n",
    "#Closure_Code\n",
    "data.Closure_Code =enc.fit_transform(data.Closure_Code )\n",
    "\n",
    "\n",
    "#Related_Interaction\n",
    "data.Related_Interaction =enc.fit_transform(data.Related_Interaction )\n",
    "\n",
    "data['No_of_Reassignments'] = data['No_of_Reassignments'].astype(int)\n",
    "data['Handle_Time_hrs'] = data['Handle_Time_hrs'].astype(str)\n",
    "data['No_of_Related_Interactions'] = data['No_of_Related_Interactions'].astype(int)\n",
    "#No_of_Reassignments\n",
    "data.No_of_Reassignments =enc.fit_transform(data.No_of_Reassignments )\n",
    "\n",
    "#Handle_Time_hrs\n",
    "data.Handle_Time_hrs =enc.fit_transform(data.Handle_Time_hrs )\n",
    "\n",
    "\n",
    "#No_of_Related_Interactions\n",
    "data.No_of_Related_Interactions =enc.fit_transform(data.No_of_Related_Interactions )\n",
    "\n",
    "data.info()\n",
    "\n",
    "corr_data=data[['CI_Cat', 'CI_Subcat', 'WBS', 'Incident_ID', 'Status', 'Impact',\n",
    "       'Urgency', 'Priority', 'number_cnt', 'Category', 'KB_number',\n",
    "       'No_of_Reassignments', 'Open_Time', 'Resolved_Time', 'Close_Time',\n",
    "       'Handle_Time_hrs', 'Closure_Code', 'No_of_Related_Interactions',\n",
    "       'Related_Interaction']]\n",
    "plt.figure(figsize=(23,25))\n",
    "sns.heatmap(corr_data.corr(),annot=True)\n",
    "\n",
    "plt.figure(figsize=(14, 14))\n",
    "plotnumber = 1\n",
    "\n",
    "for i in data:\n",
    "    plt.subplot(6, 6, plotnumber)\n",
    "    sns.boxplot(x=data[i])\n",
    "    plotnumber += 1\n",
    "    if plotnumber > 27:\n",
    "        break\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "X=data.drop('Priority',axis=1)\n",
    "y=data.Priority\n",
    "\n",
    "X.shape\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "X_train\n",
    "X_test\n",
    "y_train\n",
    "y_test\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Let's see oue target variable is balanced or not if it's not balanced. So, we have to apply SMOTE for balanced the data.\n",
    "y.value_counts()\n",
    "# here we can see our target variable is not balanced.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Creating a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Training the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the testing data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculating and printing mean squared error (MSE)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculating R-squared\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor  # Importing DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # Importing regression metrics\n",
    "\n",
    "# Creating a DecisionTreeRegressor object with specified hyperparameters\n",
    "dt = DecisionTreeRegressor(max_depth=10, min_samples_split=30, min_samples_leaf=20, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_hat = dt.predict(X_test)\n",
    "\n",
    "# Evaluating the model using Mean Squared Error (MSE) and R-squared\n",
    "mse = mean_squared_error(y_test, y_hat)\n",
    "r2 = r2_score(y_test, y_hat)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Training score\n",
    "y_train_predict = dt.predict(X_train)\n",
    "mse_train = mean_squared_error(y_train, y_train_predict)\n",
    "r2_train = r2_score(y_train, y_train_predict)\n",
    "\n",
    "print(\"Mean Squared Error (Training):\", mse_train)\n",
    "print(\"R-squared (Training):\", r2_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_hat = dt.predict(X_test)\n",
    "\n",
    "# Evaluating the model using Mean Squared Error (MSE) and R-squared\n",
    "mse = mean_squared_error(y_test, y_hat)\n",
    "r2 = r2_score(y_test, y_hat)\n",
    "\n",
    "print(\"Mean Squared Error (Test):\", mse)\n",
    "print(\"R-squared (Test):\", r2)\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Create a DecisionTreeRegressor object\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Perform hyperparameter tuning on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Use the best model for predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "y_hat = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using Mean Squared Error (MSE) and R-squared\n",
    "mse = mean_squared_error(y_test, y_hat)\n",
    "r2 = r2_score(y_test, y_hat)\n",
    "print(\"Mean Squared Error (Test):\", mse)\n",
    "print(\"R-squared (Test):\", r2)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Creating a RandomForestRegressor object with 100 decision trees\n",
    "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = rf_reg.predict(X_test)\n",
    "\n",
    "# Calculating the F1-score (this will result in an error since F1-score is for classification)\n",
    "# f_score = f1_score(y_test, y_pred)\n",
    "\n",
    "# Instead, let's evaluate the model using Mean Squared Error (MSE) and R-squared\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=5)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=5)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [30, 25, 10]\n",
    "min_samples_leaf = [5, 10, 15]\n",
    "bootstrap = [True]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'bootstrap': bootstrap\n",
    "}\n",
    "\n",
    "# Create the base model\n",
    "rf_reg1 = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "rf_cv = RandomizedSearchCV(\n",
    "    estimator=rf_reg1,\n",
    "    scoring={'mse': 'neg_mean_squared_error', 'r2': 'r2'},  # Use MSE and R2 as scoring metrics\n",
    "    refit='mse',  # Choose one of the scoring metrics for refitting\n",
    "    param_distributions=random_grid,\n",
    "    n_iter=100,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV to the data\n",
    "rf_cv.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "rf_best_params = rf_cv.best_params_\n",
    "print(f\"Best parameters: {rf_best_params}\")\n",
    "\n",
    "# Create the RandomForestRegressor with the best parameters\n",
    "rf_reg2 = RandomForestRegressor(**rf_best_params)\n",
    "\n",
    "# Train the model with the best parameters\n",
    "rf_reg2.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_predict = rf_reg2.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_predict)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculate the R-squared (R2)\n",
    "r2 = r2_score(y_test, y_predict)\n",
    "print(\"R-squared:\", r2)\n",
    "from sklearn.ensemble import GradientBoostingRegressor  # Import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # Import mean_squared_error and r2_score for regression\n",
    "\n",
    "# Model creation\n",
    "gbm = GradientBoostingRegressor()  # Object creation\n",
    "\n",
    "# Fit the model\n",
    "gbm.fit(X_train, y_train)  # Fit the data\n",
    "\n",
    "# Predict on the test set\n",
    "y_gbm = gbm.predict(X_test)  # Predict prices\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_gbm)  # Calculate Mean Squared Error\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_gbm)  # Calculate R-squared\n",
    "\n",
    "mse, r2  # Print Mean Squared Error and R-squared\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Creating a Gradient Boosting Regressor\n",
    "gbm = GradientBoostingRegressor()\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],  # Number of boosting stages to be run\n",
    "    'learning_rate': [0.05, 0.1, 0.2],  # Learning rate shrinks the contribution of each tree\n",
    "    'max_depth': [3, 4, 5]  # Maximum depth of the individual estimators\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=gbm, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Use the best model for predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared:\", r2)\n",
    "from xgboost import XGBRegressor  # Import XGBRegressor for regression\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # Import mean_squared_error and r2_score for evaluation\n",
    "\n",
    "# Model creation\n",
    "xgb_r = XGBRegressor()  # Object creation\n",
    "\n",
    "# Fit the model\n",
    "xgb_r.fit(X_train, y_train)  # Fit the data\n",
    "\n",
    "# Predict on the test set\n",
    "y_hat = xgb_r.predict(X_test)  # Predict prices\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_hat)  # Calculate MSE\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_hat)  # Calculate R-squared\n",
    "\n",
    "mse, r2  # Print MSE and R-squared\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "param_grid = {'gamma': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4, 200],\n",
    "              'learning_rate': [0.01, 0.03, 0.06, 0.1, 0.15, 0.2, 0.25, 0.300000012, 0.4, 0.5, 0.6, 0.7],\n",
    "              'max_depth': [5,6,7,8,9,10,11,12,13,14],\n",
    "              'n_estimators': [50,65,80,100,115,130,150],\n",
    "              'reg_alpha': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200],\n",
    "              'reg_lambda': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200]}\n",
    "\n",
    "# Initialize XGBRegressor\n",
    "XGB = XGBRegressor(random_state=42, verbosity=0, silent=0)\n",
    "\n",
    "# RandomizedSearchCV\n",
    "rcv = RandomizedSearchCV(estimator=XGB, scoring='neg_mean_squared_error', param_distributions=param_grid, \n",
    "                         n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "                        \n",
    "rcv.fit(X_train, y_train)  # Training data on RandomizedSearchCV\n",
    "\n",
    "cv_best_params = rcv.best_params_  # Get best parameters\n",
    "print(f\"Best parameters: {cv_best_params}\")\n",
    "\n",
    "# Initialize XGBRegressor with best parameters\n",
    "XGB2 = XGBRegressor(**cv_best_params)\n",
    "XGB2.fit(X_train, y_train)  # Training\n",
    "\n",
    "y_predict = XGB2.predict(X_test)  # Testing\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_predict)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_predict)\n",
    "\n",
    "mse, r2  # Print MSE and R-squared\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Create MLPRegressor model\n",
    "model = MLPRegressor(hidden_layer_sizes=(50, 3),\n",
    "                     learning_rate_init=0.1,\n",
    "                     max_iter=100,\n",
    "                     random_state=10)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict target values for the test set\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "# Predict target values for the training set (optional, for evaluation)\n",
    "y_train_predict = model.predict(X_train)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "mse_train = mean_squared_error(y_train, y_train_predict)\n",
    "mse_test = mean_squared_error(y_test, y_predict)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculating R-squared\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R-squared:\", r2)\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# X = Your feature matrix\n",
    "# y = Your target vector\n",
    "\n",
    "# Initialize SVM regressor\n",
    "svm_regressor = SVR(kernel='linear', C=1.0)\n",
    "\n",
    "# Train the regressor on the training data\n",
    "svm_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict target values for the test set\n",
    "y_pred = svm_regressor.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared:\", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
